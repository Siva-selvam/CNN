{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 1.0801 - accuracy: 0.6667 - val_loss: 1.1101 - val_accuracy: 0.5333\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0779 - accuracy: 0.6667 - val_loss: 1.1074 - val_accuracy: 0.5333\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0757 - accuracy: 0.6750 - val_loss: 1.1047 - val_accuracy: 0.5333\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0736 - accuracy: 0.6750 - val_loss: 1.1018 - val_accuracy: 0.5667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0715 - accuracy: 0.6750 - val_loss: 1.0990 - val_accuracy: 0.5667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0693 - accuracy: 0.6750 - val_loss: 1.0966 - val_accuracy: 0.5667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0673 - accuracy: 0.6750 - val_loss: 1.0941 - val_accuracy: 0.5667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0654 - accuracy: 0.6750 - val_loss: 1.0916 - val_accuracy: 0.5667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0635 - accuracy: 0.6750 - val_loss: 1.0895 - val_accuracy: 0.5667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0614 - accuracy: 0.6750 - val_loss: 1.0878 - val_accuracy: 0.6000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0597 - accuracy: 0.6750 - val_loss: 1.0859 - val_accuracy: 0.6000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0580 - accuracy: 0.6750 - val_loss: 1.0839 - val_accuracy: 0.6000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0564 - accuracy: 0.6750 - val_loss: 1.0818 - val_accuracy: 0.6000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0545 - accuracy: 0.6750 - val_loss: 1.0801 - val_accuracy: 0.6000\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0529 - accuracy: 0.6750 - val_loss: 1.0783 - val_accuracy: 0.6000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0512 - accuracy: 0.6750 - val_loss: 1.0764 - val_accuracy: 0.6000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0494 - accuracy: 0.6750 - val_loss: 1.0745 - val_accuracy: 0.6000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0478 - accuracy: 0.6833 - val_loss: 1.0727 - val_accuracy: 0.6000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0461 - accuracy: 0.6833 - val_loss: 1.0709 - val_accuracy: 0.6000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0443 - accuracy: 0.6917 - val_loss: 1.0691 - val_accuracy: 0.6000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0427 - accuracy: 0.6917 - val_loss: 1.0671 - val_accuracy: 0.6000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0409 - accuracy: 0.6917 - val_loss: 1.0653 - val_accuracy: 0.6000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0391 - accuracy: 0.6917 - val_loss: 1.0636 - val_accuracy: 0.6000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0375 - accuracy: 0.6917 - val_loss: 1.0617 - val_accuracy: 0.6000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0357 - accuracy: 0.6917 - val_loss: 1.0598 - val_accuracy: 0.6000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0339 - accuracy: 0.6917 - val_loss: 1.0580 - val_accuracy: 0.6000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0321 - accuracy: 0.6917 - val_loss: 1.0563 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0303 - accuracy: 0.6917 - val_loss: 1.0544 - val_accuracy: 0.5667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0285 - accuracy: 0.6917 - val_loss: 1.0525 - val_accuracy: 0.5667\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0267 - accuracy: 0.6917 - val_loss: 1.0506 - val_accuracy: 0.5667\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0248 - accuracy: 0.6917 - val_loss: 1.0489 - val_accuracy: 0.5667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0229 - accuracy: 0.6917 - val_loss: 1.0473 - val_accuracy: 0.6000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0211 - accuracy: 0.6917 - val_loss: 1.0457 - val_accuracy: 0.6333\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0191 - accuracy: 0.6917 - val_loss: 1.0438 - val_accuracy: 0.6333\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0172 - accuracy: 0.7000 - val_loss: 1.0418 - val_accuracy: 0.6333\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0152 - accuracy: 0.7000 - val_loss: 1.0401 - val_accuracy: 0.6333\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0132 - accuracy: 0.7000 - val_loss: 1.0381 - val_accuracy: 0.6333\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0112 - accuracy: 0.7000 - val_loss: 1.0363 - val_accuracy: 0.6333\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0091 - accuracy: 0.7000 - val_loss: 1.0344 - val_accuracy: 0.6333\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0071 - accuracy: 0.7000 - val_loss: 1.0326 - val_accuracy: 0.6333\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0050 - accuracy: 0.7000 - val_loss: 1.0307 - val_accuracy: 0.6333\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0029 - accuracy: 0.7000 - val_loss: 1.0287 - val_accuracy: 0.6333\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0007 - accuracy: 0.7000 - val_loss: 1.0266 - val_accuracy: 0.6333\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9985 - accuracy: 0.7000 - val_loss: 1.0246 - val_accuracy: 0.6333\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9963 - accuracy: 0.7000 - val_loss: 1.0225 - val_accuracy: 0.6333\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9941 - accuracy: 0.7000 - val_loss: 1.0205 - val_accuracy: 0.6333\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9918 - accuracy: 0.7000 - val_loss: 1.0185 - val_accuracy: 0.6333\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9896 - accuracy: 0.7000 - val_loss: 1.0164 - val_accuracy: 0.6333\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9873 - accuracy: 0.7000 - val_loss: 1.0144 - val_accuracy: 0.6333\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9850 - accuracy: 0.7000 - val_loss: 1.0123 - val_accuracy: 0.6333\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9827 - accuracy: 0.7000 - val_loss: 1.0102 - val_accuracy: 0.6333\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9803 - accuracy: 0.7083 - val_loss: 1.0081 - val_accuracy: 0.6333\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9779 - accuracy: 0.7167 - val_loss: 1.0058 - val_accuracy: 0.6333\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9754 - accuracy: 0.7167 - val_loss: 1.0037 - val_accuracy: 0.6333\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9730 - accuracy: 0.7167 - val_loss: 1.0015 - val_accuracy: 0.6333\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9706 - accuracy: 0.7167 - val_loss: 0.9994 - val_accuracy: 0.6333\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9680 - accuracy: 0.7167 - val_loss: 0.9973 - val_accuracy: 0.6333\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9656 - accuracy: 0.7167 - val_loss: 0.9951 - val_accuracy: 0.6333\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9629 - accuracy: 0.7167 - val_loss: 0.9928 - val_accuracy: 0.6333\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9604 - accuracy: 0.7167 - val_loss: 0.9904 - val_accuracy: 0.6333\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9578 - accuracy: 0.7167 - val_loss: 0.9880 - val_accuracy: 0.6333\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9552 - accuracy: 0.7167 - val_loss: 0.9855 - val_accuracy: 0.6333\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9525 - accuracy: 0.7167 - val_loss: 0.9833 - val_accuracy: 0.6333\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9498 - accuracy: 0.7167 - val_loss: 0.9810 - val_accuracy: 0.6333\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9471 - accuracy: 0.7167 - val_loss: 0.9786 - val_accuracy: 0.6333\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9443 - accuracy: 0.7167 - val_loss: 0.9763 - val_accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9416 - accuracy: 0.7167 - val_loss: 0.9741 - val_accuracy: 0.6333\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9388 - accuracy: 0.7167 - val_loss: 0.9717 - val_accuracy: 0.6333\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9360 - accuracy: 0.7167 - val_loss: 0.9693 - val_accuracy: 0.6333\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9331 - accuracy: 0.7167 - val_loss: 0.9669 - val_accuracy: 0.6333\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9302 - accuracy: 0.7167 - val_loss: 0.9644 - val_accuracy: 0.6333\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9273 - accuracy: 0.7167 - val_loss: 0.9619 - val_accuracy: 0.6333\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9245 - accuracy: 0.7167 - val_loss: 0.9594 - val_accuracy: 0.6333\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9215 - accuracy: 0.7167 - val_loss: 0.9569 - val_accuracy: 0.6333\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9185 - accuracy: 0.7167 - val_loss: 0.9545 - val_accuracy: 0.6333\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9157 - accuracy: 0.7167 - val_loss: 0.9521 - val_accuracy: 0.6333\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9125 - accuracy: 0.7167 - val_loss: 0.9495 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9095 - accuracy: 0.7167 - val_loss: 0.9468 - val_accuracy: 0.6333\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9065 - accuracy: 0.7167 - val_loss: 0.9440 - val_accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9034 - accuracy: 0.7167 - val_loss: 0.9415 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9003 - accuracy: 0.7167 - val_loss: 0.9388 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8972 - accuracy: 0.7167 - val_loss: 0.9361 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8941 - accuracy: 0.7167 - val_loss: 0.9335 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8909 - accuracy: 0.7167 - val_loss: 0.9308 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8877 - accuracy: 0.7167 - val_loss: 0.9282 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8846 - accuracy: 0.7167 - val_loss: 0.9255 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8813 - accuracy: 0.7167 - val_loss: 0.9226 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8780 - accuracy: 0.7167 - val_loss: 0.9198 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8749 - accuracy: 0.7167 - val_loss: 0.9170 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8715 - accuracy: 0.7167 - val_loss: 0.9141 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8683 - accuracy: 0.7167 - val_loss: 0.9111 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8650 - accuracy: 0.7167 - val_loss: 0.9082 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8616 - accuracy: 0.7167 - val_loss: 0.9053 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8584 - accuracy: 0.7167 - val_loss: 0.9023 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8550 - accuracy: 0.7167 - val_loss: 0.8994 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8517 - accuracy: 0.7167 - val_loss: 0.8963 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8484 - accuracy: 0.7167 - val_loss: 0.8935 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8450 - accuracy: 0.7167 - val_loss: 0.8906 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8416 - accuracy: 0.7167 - val_loss: 0.8876 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8384 - accuracy: 0.7167 - val_loss: 0.8847 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8349 - accuracy: 0.7167 - val_loss: 0.8814 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8314 - accuracy: 0.7167 - val_loss: 0.8783 - val_accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8281 - accuracy: 0.7167 - val_loss: 0.8752 - val_accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8247 - accuracy: 0.7167 - val_loss: 0.8722 - val_accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8213 - accuracy: 0.7167 - val_loss: 0.8690 - val_accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8178 - accuracy: 0.7167 - val_loss: 0.8662 - val_accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8145 - accuracy: 0.7167 - val_loss: 0.8633 - val_accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8110 - accuracy: 0.7167 - val_loss: 0.8604 - val_accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8076 - accuracy: 0.7167 - val_loss: 0.8573 - val_accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8042 - accuracy: 0.7167 - val_loss: 0.8543 - val_accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8008 - accuracy: 0.7167 - val_loss: 0.8514 - val_accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7973 - accuracy: 0.7167 - val_loss: 0.8483 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7940 - accuracy: 0.7167 - val_loss: 0.8455 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7905 - accuracy: 0.7167 - val_loss: 0.8426 - val_accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7870 - accuracy: 0.7167 - val_loss: 0.8396 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7837 - accuracy: 0.7167 - val_loss: 0.8367 - val_accuracy: 0.6667\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7801 - accuracy: 0.7167 - val_loss: 0.8335 - val_accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7770 - accuracy: 0.7167 - val_loss: 0.8301 - val_accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7733 - accuracy: 0.7167 - val_loss: 0.8272 - val_accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7699 - accuracy: 0.7167 - val_loss: 0.8241 - val_accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7665 - accuracy: 0.7167 - val_loss: 0.8212 - val_accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7631 - accuracy: 0.7167 - val_loss: 0.8182 - val_accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7597 - accuracy: 0.7167 - val_loss: 0.8152 - val_accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7564 - accuracy: 0.7167 - val_loss: 0.8122 - val_accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7530 - accuracy: 0.7167 - val_loss: 0.8090 - val_accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7496 - accuracy: 0.7167 - val_loss: 0.8061 - val_accuracy: 0.6667\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7463 - accuracy: 0.7167 - val_loss: 0.8032 - val_accuracy: 0.6667\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7429 - accuracy: 0.7167 - val_loss: 0.8002 - val_accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7395 - accuracy: 0.7167 - val_loss: 0.7972 - val_accuracy: 0.6667\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7363 - accuracy: 0.7167 - val_loss: 0.7944 - val_accuracy: 0.6667\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7329 - accuracy: 0.7167 - val_loss: 0.7915 - val_accuracy: 0.6667\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7296 - accuracy: 0.7167 - val_loss: 0.7885 - val_accuracy: 0.6667\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7263 - accuracy: 0.7167 - val_loss: 0.7856 - val_accuracy: 0.6667\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7230 - accuracy: 0.7250 - val_loss: 0.7825 - val_accuracy: 0.6667\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7197 - accuracy: 0.7250 - val_loss: 0.7796 - val_accuracy: 0.6667\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7165 - accuracy: 0.7250 - val_loss: 0.7766 - val_accuracy: 0.6667\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7132 - accuracy: 0.7250 - val_loss: 0.7736 - val_accuracy: 0.6667\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7100 - accuracy: 0.7250 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7068 - accuracy: 0.7250 - val_loss: 0.7673 - val_accuracy: 0.6667\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7036 - accuracy: 0.7250 - val_loss: 0.7643 - val_accuracy: 0.6667\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7004 - accuracy: 0.7250 - val_loss: 0.7615 - val_accuracy: 0.6667\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6973 - accuracy: 0.7250 - val_loss: 0.7586 - val_accuracy: 0.6667\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6941 - accuracy: 0.7250 - val_loss: 0.7555 - val_accuracy: 0.6667\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6909 - accuracy: 0.7250 - val_loss: 0.7526 - val_accuracy: 0.6667\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6637 - accuracy: 0.84 - 0s 12ms/step - loss: 0.6879 - accuracy: 0.7250 - val_loss: 0.7499 - val_accuracy: 0.6667\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6848 - accuracy: 0.7250 - val_loss: 0.7470 - val_accuracy: 0.6667\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6817 - accuracy: 0.7250 - val_loss: 0.7442 - val_accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6787 - accuracy: 0.7250 - val_loss: 0.7413 - val_accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6756 - accuracy: 0.7333 - val_loss: 0.7384 - val_accuracy: 0.6667\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6726 - accuracy: 0.7333 - val_loss: 0.7357 - val_accuracy: 0.6667\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6696 - accuracy: 0.7333 - val_loss: 0.7329 - val_accuracy: 0.6667\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.7333 - val_loss: 0.7303 - val_accuracy: 0.6667\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6637 - accuracy: 0.7333 - val_loss: 0.7275 - val_accuracy: 0.6667\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6607 - accuracy: 0.7333 - val_loss: 0.7246 - val_accuracy: 0.6667\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6578 - accuracy: 0.7333 - val_loss: 0.7218 - val_accuracy: 0.7000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6550 - accuracy: 0.7333 - val_loss: 0.7190 - val_accuracy: 0.7000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.7333 - val_loss: 0.7163 - val_accuracy: 0.7000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6493 - accuracy: 0.7333 - val_loss: 0.7139 - val_accuracy: 0.7000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6464 - accuracy: 0.7333 - val_loss: 0.7113 - val_accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6436 - accuracy: 0.7333 - val_loss: 0.7086 - val_accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6408 - accuracy: 0.7333 - val_loss: 0.7059 - val_accuracy: 0.7000\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6382 - accuracy: 0.7333 - val_loss: 0.7035 - val_accuracy: 0.7000\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6353 - accuracy: 0.7333 - val_loss: 0.7007 - val_accuracy: 0.7000\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6326 - accuracy: 0.7417 - val_loss: 0.6981 - val_accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6299 - accuracy: 0.7417 - val_loss: 0.6954 - val_accuracy: 0.7000\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6273 - accuracy: 0.7500 - val_loss: 0.6928 - val_accuracy: 0.7000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6246 - accuracy: 0.7500 - val_loss: 0.6900 - val_accuracy: 0.7000\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6220 - accuracy: 0.7500 - val_loss: 0.6874 - val_accuracy: 0.7000\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6194 - accuracy: 0.7500 - val_loss: 0.6849 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6168 - accuracy: 0.7500 - val_loss: 0.6825 - val_accuracy: 0.7000\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.7500 - val_loss: 0.6801 - val_accuracy: 0.7000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.6776 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.6752 - val_accuracy: 0.7000\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6067 - accuracy: 0.7500 - val_loss: 0.6728 - val_accuracy: 0.7000\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6043 - accuracy: 0.7500 - val_loss: 0.6702 - val_accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6017 - accuracy: 0.7500 - val_loss: 0.6679 - val_accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5993 - accuracy: 0.7500 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5969 - accuracy: 0.7500 - val_loss: 0.6630 - val_accuracy: 0.7333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5945 - accuracy: 0.7500 - val_loss: 0.6605 - val_accuracy: 0.7333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5921 - accuracy: 0.7500 - val_loss: 0.6583 - val_accuracy: 0.7333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5898 - accuracy: 0.7500 - val_loss: 0.6559 - val_accuracy: 0.7333\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6084 - accuracy: 0.71 - 0s 11ms/step - loss: 0.5874 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.7333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5851 - accuracy: 0.7500 - val_loss: 0.6510 - val_accuracy: 0.7333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5828 - accuracy: 0.7500 - val_loss: 0.6487 - val_accuracy: 0.7333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5805 - accuracy: 0.7500 - val_loss: 0.6464 - val_accuracy: 0.7333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5782 - accuracy: 0.7500 - val_loss: 0.6441 - val_accuracy: 0.7333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5760 - accuracy: 0.7500 - val_loss: 0.6419 - val_accuracy: 0.7333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5738 - accuracy: 0.7500 - val_loss: 0.6396 - val_accuracy: 0.7333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5716 - accuracy: 0.7500 - val_loss: 0.6374 - val_accuracy: 0.7333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.6352 - val_accuracy: 0.7333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5672 - accuracy: 0.7500 - val_loss: 0.6330 - val_accuracy: 0.7333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5652 - accuracy: 0.7500 - val_loss: 0.6306 - val_accuracy: 0.7333\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.6284 - val_accuracy: 0.7333\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5609 - accuracy: 0.7500 - val_loss: 0.6264 - val_accuracy: 0.7333\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5588 - accuracy: 0.7500 - val_loss: 0.6244 - val_accuracy: 0.7333\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5567 - accuracy: 0.7500 - val_loss: 0.6222 - val_accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5547 - accuracy: 0.7583 - val_loss: 0.6202 - val_accuracy: 0.7333\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5526 - accuracy: 0.7583 - val_loss: 0.6180 - val_accuracy: 0.7333\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5506 - accuracy: 0.7583 - val_loss: 0.6161 - val_accuracy: 0.7333\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5486 - accuracy: 0.7583 - val_loss: 0.6140 - val_accuracy: 0.7333\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5467 - accuracy: 0.7583 - val_loss: 0.6119 - val_accuracy: 0.7333\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5447 - accuracy: 0.7583 - val_loss: 0.6099 - val_accuracy: 0.7333\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5428 - accuracy: 0.7583 - val_loss: 0.6081 - val_accuracy: 0.7333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5409 - accuracy: 0.7583 - val_loss: 0.6061 - val_accuracy: 0.7333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5390 - accuracy: 0.7583 - val_loss: 0.6043 - val_accuracy: 0.7333\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5372 - accuracy: 0.7583 - val_loss: 0.6022 - val_accuracy: 0.7333\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5353 - accuracy: 0.7583 - val_loss: 0.6003 - val_accuracy: 0.7333\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5335 - accuracy: 0.7583 - val_loss: 0.5983 - val_accuracy: 0.7333\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5317 - accuracy: 0.7667 - val_loss: 0.5964 - val_accuracy: 0.7333\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5299 - accuracy: 0.7667 - val_loss: 0.5947 - val_accuracy: 0.7333\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5281 - accuracy: 0.7667 - val_loss: 0.5928 - val_accuracy: 0.7333\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5264 - accuracy: 0.7667 - val_loss: 0.5911 - val_accuracy: 0.7333\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5246 - accuracy: 0.7667 - val_loss: 0.5891 - val_accuracy: 0.7333\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5229 - accuracy: 0.7667 - val_loss: 0.5872 - val_accuracy: 0.7333\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5212 - accuracy: 0.7750 - val_loss: 0.5853 - val_accuracy: 0.7333\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5194 - accuracy: 0.7750 - val_loss: 0.5835 - val_accuracy: 0.7333\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5178 - accuracy: 0.7750 - val_loss: 0.5816 - val_accuracy: 0.7333\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5161 - accuracy: 0.7750 - val_loss: 0.5798 - val_accuracy: 0.7333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5145 - accuracy: 0.7750 - val_loss: 0.5781 - val_accuracy: 0.7333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5128 - accuracy: 0.7750 - val_loss: 0.5764 - val_accuracy: 0.7333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5113 - accuracy: 0.7833 - val_loss: 0.5745 - val_accuracy: 0.7333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5096 - accuracy: 0.7833 - val_loss: 0.5729 - val_accuracy: 0.7333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5081 - accuracy: 0.7833 - val_loss: 0.5713 - val_accuracy: 0.7333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5065 - accuracy: 0.7917 - val_loss: 0.5695 - val_accuracy: 0.7333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5049 - accuracy: 0.7917 - val_loss: 0.5679 - val_accuracy: 0.7333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5034 - accuracy: 0.7917 - val_loss: 0.5663 - val_accuracy: 0.7333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5019 - accuracy: 0.7917 - val_loss: 0.5646 - val_accuracy: 0.7333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5004 - accuracy: 0.7917 - val_loss: 0.5631 - val_accuracy: 0.7333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4989 - accuracy: 0.7917 - val_loss: 0.5616 - val_accuracy: 0.7333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4974 - accuracy: 0.7917 - val_loss: 0.5599 - val_accuracy: 0.7333\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4959 - accuracy: 0.7917 - val_loss: 0.5584 - val_accuracy: 0.7333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4945 - accuracy: 0.8000 - val_loss: 0.5568 - val_accuracy: 0.7333\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4931 - accuracy: 0.8000 - val_loss: 0.5552 - val_accuracy: 0.7333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4916 - accuracy: 0.7917 - val_loss: 0.5536 - val_accuracy: 0.7333\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4902 - accuracy: 0.7917 - val_loss: 0.5521 - val_accuracy: 0.7333\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4888 - accuracy: 0.8000 - val_loss: 0.5505 - val_accuracy: 0.7333\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4874 - accuracy: 0.8000 - val_loss: 0.5490 - val_accuracy: 0.7333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.8000 - val_loss: 0.5475 - val_accuracy: 0.7333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4847 - accuracy: 0.8000 - val_loss: 0.5461 - val_accuracy: 0.7333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4833 - accuracy: 0.8000 - val_loss: 0.5445 - val_accuracy: 0.7333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4820 - accuracy: 0.8000 - val_loss: 0.5431 - val_accuracy: 0.7333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4807 - accuracy: 0.8000 - val_loss: 0.5416 - val_accuracy: 0.7333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4794 - accuracy: 0.8083 - val_loss: 0.5401 - val_accuracy: 0.7333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4780 - accuracy: 0.8083 - val_loss: 0.5388 - val_accuracy: 0.7333\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4768 - accuracy: 0.8083 - val_loss: 0.5375 - val_accuracy: 0.7333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4755 - accuracy: 0.8083 - val_loss: 0.5362 - val_accuracy: 0.7333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4742 - accuracy: 0.8083 - val_loss: 0.5346 - val_accuracy: 0.7333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4730 - accuracy: 0.8083 - val_loss: 0.5331 - val_accuracy: 0.8000\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4717 - accuracy: 0.8083 - val_loss: 0.5317 - val_accuracy: 0.8333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4704 - accuracy: 0.8083 - val_loss: 0.5305 - val_accuracy: 0.8333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4692 - accuracy: 0.8083 - val_loss: 0.5292 - val_accuracy: 0.8333\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4680 - accuracy: 0.8083 - val_loss: 0.5279 - val_accuracy: 0.8333\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4668 - accuracy: 0.8083 - val_loss: 0.5264 - val_accuracy: 0.8333\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4656 - accuracy: 0.8083 - val_loss: 0.5249 - val_accuracy: 0.8333\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4644 - accuracy: 0.8083 - val_loss: 0.5234 - val_accuracy: 0.8333\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4632 - accuracy: 0.8083 - val_loss: 0.5221 - val_accuracy: 0.8333\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4620 - accuracy: 0.8167 - val_loss: 0.5208 - val_accuracy: 0.8333\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4608 - accuracy: 0.8167 - val_loss: 0.5194 - val_accuracy: 0.8333\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4597 - accuracy: 0.8167 - val_loss: 0.5180 - val_accuracy: 0.8333\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4587 - accuracy: 0.8167 - val_loss: 0.5166 - val_accuracy: 0.8333\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.8167 - val_loss: 0.5156 - val_accuracy: 0.8333\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4563 - accuracy: 0.8167 - val_loss: 0.5143 - val_accuracy: 0.8333\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4553 - accuracy: 0.8167 - val_loss: 0.5132 - val_accuracy: 0.8333\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4542 - accuracy: 0.8167 - val_loss: 0.5118 - val_accuracy: 0.8333\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4531 - accuracy: 0.8167 - val_loss: 0.5105 - val_accuracy: 0.8333\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4520 - accuracy: 0.8167 - val_loss: 0.5094 - val_accuracy: 0.8333\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4509 - accuracy: 0.8167 - val_loss: 0.5081 - val_accuracy: 0.8333\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4498 - accuracy: 0.8167 - val_loss: 0.5069 - val_accuracy: 0.8333\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4488 - accuracy: 0.8167 - val_loss: 0.5056 - val_accuracy: 0.8333\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4477 - accuracy: 0.8167 - val_loss: 0.5044 - val_accuracy: 0.8333\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4467 - accuracy: 0.8167 - val_loss: 0.5033 - val_accuracy: 0.8333\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4457 - accuracy: 0.8250 - val_loss: 0.5019 - val_accuracy: 0.8333\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4446 - accuracy: 0.8250 - val_loss: 0.5008 - val_accuracy: 0.8333\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4436 - accuracy: 0.8250 - val_loss: 0.4996 - val_accuracy: 0.8333\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4426 - accuracy: 0.8250 - val_loss: 0.4985 - val_accuracy: 0.8333\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4416 - accuracy: 0.8250 - val_loss: 0.4972 - val_accuracy: 0.8333\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4406 - accuracy: 0.8250 - val_loss: 0.4960 - val_accuracy: 0.8333\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4396 - accuracy: 0.8250 - val_loss: 0.4948 - val_accuracy: 0.8333\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4387 - accuracy: 0.8250 - val_loss: 0.4937 - val_accuracy: 0.8333\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4377 - accuracy: 0.8250 - val_loss: 0.4925 - val_accuracy: 0.8333\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4367 - accuracy: 0.8250 - val_loss: 0.4914 - val_accuracy: 0.8333\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4358 - accuracy: 0.8250 - val_loss: 0.4903 - val_accuracy: 0.8333\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4349 - accuracy: 0.8250 - val_loss: 0.4891 - val_accuracy: 0.8333\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4339 - accuracy: 0.8250 - val_loss: 0.4882 - val_accuracy: 0.8333\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4331 - accuracy: 0.8250 - val_loss: 0.4869 - val_accuracy: 0.8333\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4320 - accuracy: 0.8250 - val_loss: 0.4859 - val_accuracy: 0.8333\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4312 - accuracy: 0.8250 - val_loss: 0.4850 - val_accuracy: 0.8333\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4302 - accuracy: 0.8250 - val_loss: 0.4839 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4293 - accuracy: 0.8250 - val_loss: 0.4829 - val_accuracy: 0.8333\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4284 - accuracy: 0.8250 - val_loss: 0.4820 - val_accuracy: 0.8333\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.8250 - val_loss: 0.4810 - val_accuracy: 0.8333\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4266 - accuracy: 0.8250 - val_loss: 0.4801 - val_accuracy: 0.8333\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8250 - val_loss: 0.4793 - val_accuracy: 0.8333\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4249 - accuracy: 0.8250 - val_loss: 0.4783 - val_accuracy: 0.8333\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4240 - accuracy: 0.8250 - val_loss: 0.4774 - val_accuracy: 0.8333\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4232 - accuracy: 0.8250 - val_loss: 0.4764 - val_accuracy: 0.8333\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4223 - accuracy: 0.8250 - val_loss: 0.4755 - val_accuracy: 0.8333\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4215 - accuracy: 0.8250 - val_loss: 0.4744 - val_accuracy: 0.8333\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4207 - accuracy: 0.8250 - val_loss: 0.4736 - val_accuracy: 0.8333\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4198 - accuracy: 0.8250 - val_loss: 0.4726 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140a80710>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_x_train,y=y_train,epochs=300,validation_data=(scaled_x_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x142227750>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0903 - accuracy: 0.3667\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0879 - accuracy: 0.3733\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.3733\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0838 - accuracy: 0.3733\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0819 - accuracy: 0.3867\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0802 - accuracy: 0.3933\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0787 - accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0768 - accuracy: 0.4133\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0754 - accuracy: 0.4267\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0738 - accuracy: 0.4267\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0722 - accuracy: 0.4333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.4467\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0692 - accuracy: 0.4533\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.4733\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0662 - accuracy: 0.4733\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0647 - accuracy: 0.4933\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0631 - accuracy: 0.4867\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0615 - accuracy: 0.5133\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0599 - accuracy: 0.5200\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0579 - accuracy: 0.5333\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0559 - accuracy: 0.5533\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0538 - accuracy: 0.5533\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0516 - accuracy: 0.5600\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.5533\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.5933\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0440 - accuracy: 0.6067\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0413 - accuracy: 0.6200\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0384 - accuracy: 0.6400\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.6533\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.6600\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0284 - accuracy: 0.6400\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0249 - accuracy: 0.6467\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0213 - accuracy: 0.6867\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0174 - accuracy: 0.6867\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.7133\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0097 - accuracy: 0.7133\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0056 - accuracy: 0.7133\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.7067\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9974 - accuracy: 0.7067\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.6933\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.6933\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9846 - accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.7067\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.7200\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.7133\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9665 - accuracy: 0.7133\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9619 - accuracy: 0.7133\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9572 - accuracy: 0.7067\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.7067\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.7067\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9427 - accuracy: 0.7067\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.7067\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9330 - accuracy: 0.7067\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.7000\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9230 - accuracy: 0.6933\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9179 - accuracy: 0.6867\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9129 - accuracy: 0.6800\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.6800\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9028 - accuracy: 0.6800\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8976 - accuracy: 0.6800\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8924 - accuracy: 0.6800\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8874 - accuracy: 0.6800\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6800\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8772 - accuracy: 0.6867\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8718 - accuracy: 0.6867\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8666 - accuracy: 0.6867\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8613 - accuracy: 0.6867\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8563 - accuracy: 0.6867\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8510 - accuracy: 0.6867\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8459 - accuracy: 0.6867\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8408 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8356 - accuracy: 0.6867\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8304 - accuracy: 0.6867\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8253 - accuracy: 0.6867\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8202 - accuracy: 0.6867\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8152 - accuracy: 0.6867\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8101 - accuracy: 0.6867\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.6867\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8000 - accuracy: 0.6867\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7950 - accuracy: 0.6867\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7902 - accuracy: 0.6867\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7853 - accuracy: 0.6867\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7804 - accuracy: 0.6867\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.6867\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7707 - accuracy: 0.6867\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7661 - accuracy: 0.6867\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7613 - accuracy: 0.6867\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7567 - accuracy: 0.6867\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.6867\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7474 - accuracy: 0.6867\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7429 - accuracy: 0.6867\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7386 - accuracy: 0.6867\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7340 - accuracy: 0.6867\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7297 - accuracy: 0.6867\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.6867\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.6867\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7167 - accuracy: 0.6867\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7125 - accuracy: 0.6867\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.6867\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.6867\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7002 - accuracy: 0.6867\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6867\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.6867\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6867\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.6867\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.6867\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6867\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6733 - accuracy: 0.6867\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6867\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6867\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.6867\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6867\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6867\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6867\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6867\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.6867\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6867\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.6933\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6933\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6933\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.6933\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6933\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6933\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.6933\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.6933\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6933\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6867\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6867\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6933\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6933\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6009 - accuracy: 0.6933\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6933\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.6933\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6933\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6933\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.6933\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6933\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6933\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5810 - accuracy: 0.6933\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.6933\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6933\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.6933\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5719 - accuracy: 0.7000\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.7000\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7000\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7000\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7000\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7000\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7067\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7133\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7267\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7267\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.7267\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7333\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5474 - accuracy: 0.7333\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7333\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5437 - accuracy: 0.7333\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7333\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5401 - accuracy: 0.7333\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7333\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7333\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7333\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7333\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7333\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5299 - accuracy: 0.7333\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7333\n",
      "Epoch 167/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7333\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7333\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7333\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7333\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7400\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7467\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7533\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7533\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7533\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7533\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7533\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7533\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7533\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7533\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7533\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7533\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7533\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7600\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7667\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7667\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7667\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7667\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7800\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7867\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7933\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8000\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8000\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8133\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.8133\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8133\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8133\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8133\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.8133\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8133\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8133\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8133\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.8200\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8200\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8200\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8200\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8133\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8200\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8200\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8200\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8200\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.8200\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8200\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8200\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.8200\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8200\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.8200\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.8200\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8200\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8200\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8200\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.8200\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.8200\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.8200\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.8200\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8200\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8200\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8200\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.8200\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8200\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.8200\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8200\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8200\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4526 - accuracy: 0.8200\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8200\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8200\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.8200\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8200\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8200\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.8200\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8200\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8200\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.8200\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.8200\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.8200\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.8200\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8267\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8267\n",
      "Epoch 249/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.8267\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8267\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.8267\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8267\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8267\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8267\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8267\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8267\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8267\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.8267\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.8267\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8267\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8267\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.8267\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8267\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8267\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8267\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8267\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8267\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8267\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8200\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8067\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8133\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8267\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8267\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8333\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8333\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8333\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8467\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8533\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8533\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8533\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8467\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8533\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8533\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8600\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8667\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8667\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8667\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8733\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8733\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8800\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8867\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8867\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8867\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3807 - accuracy: 0.8867\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8867\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8867\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8867\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8933\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3730 - accuracy: 0.8933\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3715 - accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142341550>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_x,y,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "code deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
